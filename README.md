# Stock Market Streaming con Kafka y Spark

Proyecto de Big Data que simula el procesamiento en tiempo real de datos del mercado de valores utilizando Apache Kafka como sistema de mensajer칤a y Apache Spark Streaming para el an치lisis de datos.

## 游늶 Descripci칩n

Este proyecto consta de dos componentes principales:

1. **Producer (`stock_producer.py`)**: Lee datos de un dataset de acciones de Kaggle y env칤a informaci칩n aleatoria de precios a un topic de Kafka cada segundo.

2. **Consumer (`stock_streaming_consumer.py`)**: Consume los datos desde Kafka usando Spark Streaming y realiza an치lisis agregados por ventanas de tiempo de 1 minuto, calculando estad칤sticas como precio promedio, m치ximo y m칤nimo por s칤mbolo.

## 游댢 Requisitos Previos

### Software Necesario

- **Apache Kafka** (instalado en `/opt/Kafka/`)
- **Apache Spark** 4.0.1 o superior
- **Python 3.x**
- **Java** (requerido por Kafka y Spark)

### Librer칤as Python

```bash
pip install kafka-python pandas pyspark
```

## 游 Instrucciones de Ejecuci칩n

### 1. Iniciar Zookeeper

```bash
sudo /opt/Kafka/bin/zookeeper-server-start.sh /opt/Kafka/config/zookeeper.properties &
```

### 2. Iniciar Servidor Kafka

```bash
sudo /opt/Kafka/bin/kafka-server-start.sh /opt/Kafka/config/server.properties &
```

### 3. Crear el Topic

```bash
/opt/Kafka/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic stock_data
```

**Nota:** Si el topic ya existe, este paso puede omitirse.

### 4. Ejecutar el Producer

```bash
python3 stock_producer.py
```

Este script comenzar치 a enviar datos de acciones a Kafka cada segundo.

### 5. Ejecutar el Consumer (en otra terminal)

```bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.13:4.0.1 stock_streaming_consumer.py
```

El consumer mostrar치 en consola estad칤sticas agregadas por ventanas de 1 minuto.

## 游늵 Datos Procesados

El sistema procesa la siguiente informaci칩n por cada acci칩n:

- **Symbol**: S칤mbolo de la acci칩n (ej: AAPL, GOOGL)
- **Security Name**: Nombre completo de la empresa
- **Exchange**: Bolsa donde cotiza
- **Market Category**: Categor칤a de mercado
- **ETF**: Indicador si es ETF (Y/N)
- **Round Lot Size**: Tama침o del lote est치ndar
- **Price**: Precio generado aleatoriamente (simulaci칩n)
- **Timestamp**: Marca de tiempo Unix

## 游댌 An치lisis Realizado

El consumer realiza las siguientes operaciones:

1. **Limpieza de datos**: Elimina registros con valores nulos
2. **Deduplicaci칩n**: Elimina duplicados por s칤mbolo
3. **Agregaciones por ventana temporal** (1 minuto):
   - N칰mero de mensajes recibidos
   - Precio promedio
   - Precio m치ximo
   - Precio m칤nimo

## 游닇 Dataset

El proyecto utiliza el dataset [Stock Market Dataset](https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset) de Kaggle, que se descarga autom치ticamente al ejecutar el producer.

## 丘멆잺 Notas

- Aseg칰rate de que los puertos 2181 (Zookeeper) y 9092 (Kafka) est칠n disponibles
- El producer genera precios aleatorios entre 10 y 500 para simulaci칩n
- Para detener los procesos, usa `Ctrl+C` en cada terminal


